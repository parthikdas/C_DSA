<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection</title>
</head>
<body>
    <h1>Face Detection</h1>
    <video id="video" autoplay></video>
    <canvas id="canvas" height="400" width="600" style="border: 1px solid red;"></canvas>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script>
        let video = document.getElementById('video')
        let model
        let canvas = document.getElementById('canvas')
        let ctx = canvas.getContext('2d')

        const videoStream = () => {
            navigator.mediaDevices.getUserMedia({ // getUserMedia is a API and takes an object as an argument 
                video: {width: 600, height: 400},
                audio: false // make it true if u also want audio
            })
            .then((stream) => { // and this returns a stream object which is a media stream object
                video.srcObject = stream 
            })
        }

        const detectFaces = async () => { // this is function is asynchronus
            const prediction = await model.estimateFaces(video, false) // 1st arg is input, 2nd is if we want to return tensor or not So her we dont want tensor we want actual values of coordinates
            ctx.drawImage(video, 0, 0, 600, 400)
            prediction.forEach(pred => { // pred corresponds to 1 face
                ctx.beginPath()
                ctx.lineWidth = '4'
                ctx.strokeStyle = 'blue'
                ctx.rect(
                    pred.topLeft[0],
                    pred.topLeft[1],
                    pred.bottomRight[0] - pred.topLeft[0],
                    pred.bottomRight[1] - pred.topLeft[1]
                )
                ctx.stroke()
                // Now plot other points, its in landmark array
                ctx.fillStyle = 'red'
                pred.landmarks.forEach(landmark => {
                    ctx.fillRect(landmark[0], landmark[1], 5, 5)
                })
            })
        }

        videoStream();
        video.addEventListener('loadeddata', async () =>{ // After the data is loaded then canvas is called, else it will not show
            model = await blazeface.load()
            setInterval(detectFaces, 40) // 1000/24frames = 40
        })
    </script>
</body>
</html>